#!/usr/bin/env python

'''
Quinn Perfetto 2014


Grabs all images found within image tags on a given web page


Usage:

grabimages -u <page url>


It will download all images found into your current working directory

'''


import urllib2
from urlparse import urlsplit
from os.path import basename
from bs4 import BeautifulSoup
import optparse

def findImages(url): #use beautiful soup to find all of the image tags
	print "[*] Finding images on "+url
	urlContent=urllib2.urlopen(url).read()
	soup=BeautifulSoup(urlContent)
	imgTags=soup.findAll('img')
	return imgTags


def hasProtocol(fileName):
	return fileName.startswith("http://") or fileName.startswith("https://") #checking if the image is referenced locally

def downloadImage(url,imgTag):
	try:
		print "[+] Downloading image..."
		imgSrc=imgTag['src']
		if not hasProtocol(imgSrc): #if the image is referenced locally we need to fix that so we can download it
			imgSrc=url+"/"+imgSrc

		print imgSrc
		imgContent = urllib2.urlopen(imgSrc).read()
		imgFileName = basename(urlsplit(imgSrc)[2])
		imgFile = open(imgFileName, 'wb')
		imgFile.write(imgContent)
		imgFile.close()
		return imgFileName
	except Exception as e:
		
		print "[-] Download failed"
		print "[-] "+str(e)


def main():
	parser=optparse.OptionParser("Usage grabimages -u <url>")
	parser.add_option("-u",dest="url",type="string",help="Enter a URL")
	(options,args)=parser.parse_args()

	url=options.url

	if url==None:
		print parser.usage
		exit(0)


	if not hasProtocol(url):
		url="http://"+url

	images=findImages(url)




	if len(images)>0:
		for image in images:
			downloadImage(url,image)
	else:
		print "[-] No images found"


if __name__=="__main__":
	main()


